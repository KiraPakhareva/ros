# Об алгоритме обучения

В этом примере мы используем алгоритм обучения подкреплению Qlearn. Это классический алгоритм обучения подкреплению. Вы можете найти здесь \([https://en.wikipedia.org/wiki/Q-learningI0NTU3OEAxNTE4MTU5MTc4](https://en.wikipedia.org/wiki/Q-learningI0NTU3OEAxNTE4MTU5MTc4)\) его описание . Код для алгоритма Qlearn представлен в файле qlearn.py. Он был взят из git Виктора Майораля, и вы можете найти оригинальный код здесь \([https://github.com/vmayoral/basic\_reinforcement\_learning/blob/master/tutorial4/README.md](https://github.com/vmayoral/basic_reinforcement_learning/blob/master/tutorial4/README.md)\) \(спасибо Виктору за такую хорошую работу!\). Вы можете изменить этот алгоритм для другого, который вы, возможно, разработали, и это будет следующим хитом в области искусственного интеллекта. Просто создайте код \(например qlearn.py \) с теми же входами и выходами, а затем подставить вызов в файл start\_training.py. В этом и заключается величие фреймворка OpenAI: вы можете просто подключить свой алгоритм, а не менять ничего из остального, и вся система обучения все равно будет работать. Сделав это, вы можете сравнить свой алгоритм с другими при точно таких же условиях. Кроме того, мы включили в репозиторий еще один классический алгоритм обучения армированию, называемый Sarsa \( sarsa.py \).

